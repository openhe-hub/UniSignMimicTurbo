# FramerTurbo - Quick Start Guide

Welcome to FramerTurbo! This guide helps you quickly understand the project structure and usage.

## ğŸ“ Project Structure

```
FramerTurbo/
â”œâ”€â”€ ğŸ“– README.md                 # Main project documentation
â”œâ”€â”€ ğŸ“– STRUCTURE.md              # Detailed directory structure
â”œâ”€â”€ ğŸ“– QUICKSTART.md             # This file
â”‚
â”œâ”€â”€ ğŸ¨ apps/                     # Gradio interactive apps
â”‚   â””â”€â”€ app_turbo_v2.py         # Recommended (supports multiple schedulers)
â”‚
â”œâ”€â”€ ğŸ”§ scripts/                  # Script tools
â”‚   â”œâ”€â”€ inference/              # Inference scripts
â”‚   â”‚   â””â”€â”€ cli_infer_turbo_v2.py  # Recommended
â”‚   â”œâ”€â”€ slurm/                  # Cluster jobs
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ train_lora.sh       # Training launch script
â”‚
â”œâ”€â”€ ğŸ“ training/                 # LoRA fine-tuning
â”‚   â”œâ”€â”€ train_lora.py           # Training script
â”‚   â”œâ”€â”€ train_dataset.py        # Dataset implementation
â”‚   â”œâ”€â”€ train_config.py         # Configuration example
â”‚   â”œâ”€â”€ infer_with_lora.py      # LoRA inference
â”‚   â”œâ”€â”€ batch_infer_with_lora.py # Batch LoRA inference
â”‚   â””â”€â”€ validate_on_trainset.py  # Validation on training data
â”‚
â”œâ”€â”€ ğŸ—ï¸ models_diffusers/         # Model definitions
â”œâ”€â”€ ğŸ”„ pipelines/                # Pipelines
â”œâ”€â”€ ğŸ¯ gradio_demo/              # Gradio utilities
â””â”€â”€ ğŸ“¦ assets/                   # Example assets
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Inference (Generate Videos)

**Command-line Inference** (Recommended):
```bash
# Using DPM++ scheduler (balanced speed and quality)
python scripts/inference/cli_infer_turbo_v2.py \
    --input_dir assets/test_single \
    --model checkpoints/framer_512x320 \
    --output_dir outputs
```

**Graphical Interface**:
```bash
python apps/app_turbo_v2.py
```

### 2ï¸âƒ£ Training (Fine-tune Model)

See complete training documentation:
```bash
cat docs/TRAINING.md
```

Quick start training:
```bash
# 1. Prepare data (place videos in data/training_videos/)
# 2. Edit configuration
nano scripts/train/train_lora.sh

# 3. Start training
bash scripts/train/train_lora.sh
```

### 3ï¸âƒ£ Use Fine-tuned Model

```bash
python training/infer_with_lora.py \
    --lora_weights outputs/lora_finetune/final/unet_lora \
    --start_image examples/start.jpg \
    --end_image examples/end.jpg \
    --output_path output.gif
```

## ğŸ“ Common Commands

### Inference

```bash
# Basic inference (Euler, 30 steps, best quality)
python scripts/inference/cli_infer_turbo_v2.py \
    --input_dir INPUT_DIR \
    --model checkpoints/framer_512x320 \
    --scheduler euler \
    --num_inference_steps 30

# Fast inference (DPM++, 15 steps, recommended)
python scripts/inference/cli_infer_turbo_v2.py \
    --input_dir INPUT_DIR \
    --model checkpoints/framer_512x320 \
    --scheduler dpm++ \
    --num_inference_steps 15

# Ultra-fast inference (LCM, 4 steps)
python scripts/inference/cli_infer_turbo_v2.py \
    --input_dir INPUT_DIR \
    --model checkpoints/framer_512x320 \
    --scheduler lcm \
    --num_inference_steps 4

# High-resolution inference (576x576)
python scripts/inference/cli_infer_576x576.py \
    --input_dir INPUT_DIR \
    --model checkpoints/framer_576x576 \
    --output_dir outputs_hd
```

### Training

```bash
# View training configuration
cat training/train_config.py

# Edit training script
nano scripts/train/train_lora.sh

# Start training
bash scripts/train/train_lora.sh

# Train with custom parameters
python training/train_lora.py \
    --pretrained_model_path checkpoints/framer_512x320 \
    --data_dir data/my_videos \
    --output_dir outputs/my_lora \
    --train_batch_size 2 \
    --lora_rank 128 \
    --train_unet
```

## ğŸ“š Detailed Documentation

- **Project Overview**: [README.md](../README.md)
- **Directory Structure**: [STRUCTURE.md](STRUCTURE.md)
- **Training Guide**: [TRAINING.md](TRAINING.md)

## âš™ï¸ Scheduler Comparison

| Scheduler | Steps | Speed      | Quality | Use Case |
|-----------|-------|------------|---------|----------|
| Euler     | 30    | Slow       | Best    | Final production |
| DPM++     | 15    | Fast       | Excellent | Daily use (recommended) |
| LCM       | 4-6   | Ultra-fast | Good    | Quick preview |

## ğŸ’¡ Tips

1. **First-time use**: Start with the GUI (`python apps/app_turbo_v2.py`)
2. **Batch processing**: Use command-line scripts (`scripts/inference/cli_infer_turbo_v2.py`)
3. **Fine-tuning**: Refer to `docs/TRAINING.md` for detailed steps
4. **Out of memory**: Reduce batch_size, use FP16, or use smaller lora_rank

## â“ FAQ

**Q: How to switch between different app versions?**
```bash
# Original version (Euler)
python apps/app.py

# Turbo v2 (recommended, supports multiple schedulers)
python apps/app_turbo_v2.py
```

**Q: Where should training data be placed?**

Place video files in any directory, then specify the `DATA_DIR` path in the training script.

**Q: How to view all available parameters?**
```bash
python scripts/inference/cli_infer_turbo_v2.py --help
python training/train_lora.py --help
```

## ğŸ“ Get Help

- View detailed documentation: `STRUCTURE.md` and `TRAINING.md`
- Check examples: `assets/` directory
- Review configuration: `training/train_config.py`

---

**Happy Framing! ğŸ¬**
